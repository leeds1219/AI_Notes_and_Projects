{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNr+jp2EQoND+XGsyJvzTst",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leeds1219/DL_and_AI_Notes_and_Projects/blob/main/ColabPro_Project_Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNiYlyKQ3i1K"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/u/0/uc?id=1UtkewgHB_tjxEweDsxb4dtfRC4uIByHg&export=download'\n",
        "output = 'data.zip'\n",
        "gdown.download(url, output, quiet=False)\n",
        "gdown.extractall('data.zip')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "pWEks_sZ41g1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# Make word tokens a to z, ?!, 0 to 9 and a blank\n",
        "# the dataset provides intructions\n",
        "# Removed the capitals since it does not have meanings\n",
        "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz!?0123456789 \"]\n",
        "\n",
        "# tf.keras.layers.StringLookup(\n",
        "#    max_tokens=None,\n",
        "#    num_oov_indices=1,\n",
        "#    mask_token=None,\n",
        "#    oov_token='[UNK]',\n",
        "#    vocabulary=None,\n",
        "#    idf_weights=None,\n",
        "#    encoding='utf-8',\n",
        "#    invert=False,\n",
        "#    output_mode='int',\n",
        "#    sparse=False,\n",
        "#    pad_to_max_tokens=False,\n",
        "#    **kwargs\n",
        "#)\n",
        "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
        "num_to_char = tf.keras.layers.StringLookup(vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True)"
      ],
      "metadata": {
        "id": "kMYAlf1w43g3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_s1(dir:str) -> List[float]:\n",
        "\n",
        "# We want to take the path as a str and return the normalized List of float\n",
        "    Video_Capture = cv2.VideoCapture(dir)\n",
        "    frames = []\n",
        "\n",
        "# used opencv to read the video and capture the frames\n",
        "    for _ in range(int(Video_Capture.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
        "# ret(a boolean) tells if the reading was successfull(True) or not(False)\n",
        "        ret, frame = Video_Capture.read()\n",
        "\n",
        "# changed the video to grayscale save resource\n",
        "        frame = tf.image.rgb_to_grayscale(frame)\n",
        "\n",
        "# Cut the mouth part and save since we do not want to use extra resource\n",
        "# The original LipNet CTC paper used a extract_mouth_batch.py\n",
        "# To save resource we just cut the lower part of the video\n",
        "        frames.append(frame[190:236,80:220,:])\n",
        "    Video_Capture.release()\n",
        "\n",
        "# normalize the frames\n",
        "    mean = tf.math.reduce_mean(frames)\n",
        "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
        "    return tf.cast((frames - mean), tf.float32) / std"
      ],
      "metadata": {
        "id": "8omno4Y-4_N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_alignments(dir:str) -> List[str]:\n",
        "# Same as video\n",
        "    with open(dir, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "# save the tokens here\n",
        "    tokens = []\n",
        "\n",
        "# In the labe the lines separate the words in the alignment folder\n",
        "    for line in lines:\n",
        "\n",
        "# Split the lines\n",
        "        line = line.split()\n",
        "\n",
        "# If sil it has no meaning so remove\n",
        "        if line[2] != 'sil':\n",
        "            tokens = [*tokens,' ',line[2]]\n",
        "\n",
        "# char_to_num inputs take a single letter so we have to break the tokens into letters\n",
        "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]"
      ],
      "metadata": {
        "id": "6JrI5DiW5Cod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(dir: str):\n",
        "# we need decoding to use split functions\n",
        "    dir = bytes.decode(dir.numpy())\n",
        "\n",
        "# split the directory of the files\n",
        "    file_name = dir.split('/')[-1].split('.')[0]\n",
        "\n",
        "# get the video folder which is /data/s1/*.mpg\n",
        "    video_dir = os.path.join('data','s1',f'{file_name}.mpg')\n",
        "\n",
        "# get the alignments which directory is /data/alignments/s1/*.align\n",
        "    alignment_dir = os.path.join('data','alignments','s1',f'{file_name}.align')\n",
        "\n",
        "# load them with the function together\n",
        "# if we separatly load s1 and alignment we have to match them every epoch\n",
        "    frames = load_s1(video_dir)\n",
        "    alignments = load_alignments(alignment_dir)\n",
        "    return frames, alignments"
      ],
      "metadata": {
        "id": "kn3URwko5E-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A sample to test if the funcitons work\n",
        "sample_dir = '/content/data/s1/bbaf2n.mpg'"
      ],
      "metadata": {
        "id": "defg74g25GZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the type, shape of the to be input tensors\n",
        "# Frames\n",
        "frames, alignments = load_data(tf.convert_to_tensor(sample_dir))"
      ],
      "metadata": {
        "id": "6xxRvbsa5Ijq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "frames.shape"
      ],
      "metadata": {
        "id": "QNPWs4Fn5I91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alignments.shape"
      ],
      "metadata": {
        "id": "Z7W3s-Dc5LI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For tensorflow we need py_function to use str\n",
        "def mappable_function(dir:str) ->List[str]:\n",
        "    result = tf.py_function(load_data, [dir], (tf.float32, tf.int64))\n",
        "    return result"
      ],
      "metadata": {
        "id": "wzDTJHJC5Mka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list_files method allow elements of file list to be a independent data\n",
        "# and shuffles by default\n",
        "data = tf.data.Dataset.list_files('./data/s1/*.mpg')\n",
        "\n",
        "# we can also shuffle the data using .shuffle()\n",
        "# to save resource turned of shuffling every epoch\n",
        "data = data.shuffle(500, reshuffle_each_iteration=False)\n",
        "\n",
        "# {nameofdataset}.map(f) creates a new dataset with the given function f\n",
        "# we can add data augmentations here such as random rotations, resizing etc\n",
        "# returns the frames ans alignments\n",
        "# use frames, alignments = data.as_numpy_iterator().next()\n",
        "data = data.map(mappable_function)\n",
        "\n",
        "# .padded_batch(batch_size, padded_shapes=None, padding_values=None, drop_remainder=False)\n",
        "# the TensorShape([75, 46, 140, 1]) we can see that the frames are 75\n",
        "# and ensure that there are 40 tokens in the alignments if less padded to zero\n",
        "data = data.padded_batch(2, padded_shapes=([75,None,None,None],[40]))\n",
        "\n",
        "# preload as the epochs are performed hide Memory latency\n",
        "# optimize the process!\n",
        "data = data.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "CP1kYzfr5Oiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the input shape keep this!\n",
        "data.as_numpy_iterator().next()[0][0].shape"
      ],
      "metadata": {
        "id": "BJGq1U125Qe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv3D, Activation, MaxPool3D, TimeDistributed, Flatten, Bidirectional, LSTM, Dropout, Dense\n",
        "\n",
        "# Attention layer need to check dimesion of model and attention heads\n",
        "#class AttentionLayer(tf.keras.layers.Layer):\n",
        "#  def __init__(self, **kwargs):\n",
        "#    super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "#  def build(self, input_shape):\n",
        "#    self.W_q = self.add_weight(name=\"W_q\", shape=(input_shape[-1], input_shape[-1]), initializer='glorot_uniform')\n",
        "#    self.W_k = self.add_weight(name=\"W_k\", shape=(input_shape[-1], input_shape[-1]), initializer='glorot_uniform')\n",
        "#    self.W_v = self.add_weight(name=\"W_v\", shape=(input_shape[-1], input_shape[-1]), initializer='glorot_uniform')\n",
        "\n",
        "#  def call(self, x):\n",
        "#    q = tf.tensordot(x, self.W_q, axes=[-1, 0]) # Query\n",
        "#    k = tf.tensordot(x, self.W_k, axes=[-1, 0]) # Key\n",
        "#    v = tf.tensordot(x, self.W_v, axes=[-1, 0]) # Value\n",
        "\n",
        "#    attn_logits = tf.matmul(q, k, transpose_b=True)\n",
        "#    attn_logits = tf.nn.softmax(attn_logits, axis=-1)\n",
        "#    output = tf.matmul(attn_logits, v)\n",
        "#    return output\n",
        "\n",
        "# The Original LipNet paper used Spatial Pooling layer x 3, Bi-GRU x 2, linear x 1 and CTC loss fucntion\n",
        "class MyLipReadModel(Model):\n",
        "  def __init__(self, input_shape, vocabulary_size, **kwargs):\n",
        "    super(MyLipReadModel, self).__init__(**kwargs)\n",
        "\n",
        "# Conv3D layers to process video data type\n",
        "    self.conv1 = Conv3D(128, 3, padding='same', input_shape=input_shape)\n",
        "    self.relu1 = Activation('relu')\n",
        "    self.maxpool1 = MaxPool3D((1, 2, 2))\n",
        "\n",
        "    self.conv2 = Conv3D(256, 3, padding='same')\n",
        "    self.relu2 = Activation('relu')\n",
        "    self.maxpool2 = MaxPool3D((1, 2, 2))\n",
        "\n",
        "    self.conv3 = Conv3D(75, 3, padding='same')\n",
        "    self.relu3 = Activation('relu')\n",
        "    self.maxpool3 = MaxPool3D((1, 2, 2))\n",
        "\n",
        "# The original paper used two highway layers\n",
        "# Since we just want to keep the 75 frames use a TimeDistributed layer and flatten\n",
        "    self.time_dist = TimeDistributed(Flatten())\n",
        "\n",
        "# paper used bidirectional LSTM model and a CTC loss function\n",
        "# LSTM was used in most Language models so why not add it\n",
        "# The paper used the Orthogonal initializer\n",
        "# initial Dropout was set to 0.5\n",
        "    self.lstm1 = Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True))\n",
        "    self.dropout1 = Dropout(0.5)\n",
        "\n",
        "    self.lstm2 = Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True))\n",
        "    self.dropout2 = Dropout(0.5)\n",
        "\n",
        "# The Best performing paper added an additional attention layer here before the CTC\n",
        "# atten1 75x28\n",
        "#    self.attention = AttentionLayer()\n",
        "\n",
        "    self.dense = Dense(vocabulary_size + 1, kernel_initializer='he_normal', activation='softmax')\n",
        "\n",
        "# Perform forwards\n",
        "  def call(self, inputs):\n",
        "    x = self.conv1(inputs)\n",
        "    x = self.relu1(x)\n",
        "    x = self.maxpool1(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "    x = self.relu2(x)\n",
        "    x = self.maxpool2(x)\n",
        "\n",
        "    x = self.conv3(x)\n",
        "    x = self.relu3(x)\n",
        "    x = self.maxpool3(x)\n",
        "\n",
        "    x = self.time_dist(x)\n",
        "\n",
        "    x = self.lstm1(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.lstm2(x)\n",
        "    x = self.dropout2(x)\n",
        "\n",
        "#    x=self.attention(x)\n",
        "\n",
        "    output = self.dense(x)\n",
        "    return output\n",
        "\n",
        "  def summary(self):\n",
        "    x = tf.keras.layers.Input(shape = (75, 46, 140, 1))\n",
        "    model = Model(inputs = x, outputs = self.call(x))\n",
        "    return model.summary()\n",
        "\n",
        "input_shape = (75, 46, 140, 1)\n",
        "vocabulary_size = char_to_num.vocabulary_size()\n",
        "\n",
        "mymodel = MyLipReadModel(input_shape, vocabulary_size)\n",
        "mymodel.summary()"
      ],
      "metadata": {
        "id": "pU2GmRhj5Sw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "\n",
        "# Learning rate schedular\n",
        "# Step Decay\n",
        "#def step_decay(epoch):\n",
        "#    start = 0.1\n",
        "#    drop = 0.5\n",
        "#    epochs_drop = 5.0\n",
        "#    lr = start * (drop ** np.floor((epoch)/epochs_drop))\n",
        "#    return lr\n",
        "#model = Sequential([Dense(10)])\n",
        "#model.compile(optimizer=SGD(), loss='mse')\n",
        "#lr_scheduler = LearningRateScheduler(step_decay, verbose=1)\n",
        "#history = model.fit(np.arange(10).reshape(10, -1), np.zeros(10),\n",
        "#                    epochs=10, callbacks=[lr_scheduler], verbose=0)\n",
        "# Cosine Decay\n",
        "#cos_decay = tf.keras.experimental.CosineDecay(initial_learning_rate=0.001, decay_steps=50, alpha=0.001)\n",
        "#model = Sequential([Dense(10)])\n",
        "#model.compile(optimizer=SGD(cos_decay), loss='mse')\n",
        "#lr_scheduler = LearningRateScheduler(cos_decay, verbose=1)\n",
        "#history = model.fit(np.arange(10).reshape(10, -1), np.zeros(10),\n",
        "#                    epochs=10, verbose=0)\n",
        "# Cosine Decay Annealling\n",
        "#cos_decay_ann = tf.keras.experimental.CosineDecayRestarts(initial_learning_rate=0.1, first_decay_steps=10, t_mul=1, m_mul=0.9, alpha=0)\n",
        "#model = Sequential([Dense(10)])\n",
        "#model.compile(optimizer=SGD(learning_rate=cos_decay_ann), loss='mse')\n",
        "#history = model.fit(np.arange(10).reshape(10, -1), np.zeros(10),\n",
        "#                    epochs=10, verbose=0)\n",
        "# PyTorch LRs\n",
        "# ExponetialLR\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)\n",
        "#scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.5)\n",
        "#import torch\n",
        "#import torch.nn as nn\n",
        "#import torch.optim as optim\n",
        "#from data import AudioDataset, AudioDataLoader\n",
        "#from matplotlib import pyplot as plt\n",
        "\n",
        "#class Model(nn.Module):\n",
        "#    def __init__(self):\n",
        "#        super(Model, self).__init__()\n",
        "#        self.linear = nn.Linear(10, 10)\n",
        "#        self.activation = nn.ReLU()\n",
        "#    def forward(self, x):\n",
        "#        return self.activation(self.linear1(x))\n",
        "\n",
        "# data\n",
        "#tr_dataset = AudioDatset('tr')\n",
        "#data_loader = AudioDataLoader(tr_dataset, batch_size=3, shuffle=1)\n",
        "# model\n",
        "#model = Model()\n",
        "# loss\n",
        "#loss = nn.MSELoss()\n",
        "# optimizer\n",
        "#optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "#scheduler\n",
        "#scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
        "#                                        lr_lambda=lambda epoch: 0.95 ** epoch,\n",
        "#                                        last_epoch=-1,\n",
        "#                                        verbose=False)\n",
        "\n",
        "#epochs=100\n",
        "#for epoch in range(epochs):\n",
        "#    for i, (data) in enumerate(data_loader):\n",
        "#        x_data, y_data = data\n",
        "#        optimizer.zero_grad()\n",
        "\n",
        "#        estimated_y = model(x_data)\n",
        "#        loss = loss(y_data, estimated_y)\n",
        "#        loss.backward()\n",
        "#        optimizer.step()\n",
        "#    scheduler.step() # you can set it like this!\n",
        "# Cosine annealing\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "#scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=0)\n",
        "#Started with exp and change if it doesn't work\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 30:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * tf.math.exp(-0.1)"
      ],
      "metadata": {
        "id": "ld9Tk-k75VgI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}